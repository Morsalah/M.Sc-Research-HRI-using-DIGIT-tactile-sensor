{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM5PPBytdeDMg5ePZDt89ih",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Morsalah/M.Sc-Research-HRI-using-DIGIT-tactile-sensor/blob/main/binaryclassification_ongoing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import logging\n",
        "import csv\n",
        "import cv2\n",
        "import numpy as np\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "from digit_interface.digit import Digit\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from models.simple_cnn import ConvNeuralNet\n",
        "from  models.variables import learning_rate, num_classes\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "PRObi-Od9NQv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up logging\n",
        "logging.basicConfig(level=logging.DEBUG)\n",
        "logger = logging.getLogger(__name__)"
      ],
      "metadata": {
        "id": "6gLuYqSe9cYU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. creating directory\n"
      ],
      "metadata": {
        "id": "e9s9noPe-POH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to create directories\n",
        "def create_directory(path: str):\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)\n",
        "        logger.info(f\"Directory {path} created.\")"
      ],
      "metadata": {
        "id": "vbBArU9e9dqk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. labeling captured images by SSIM and pixel intensity difference"
      ],
      "metadata": {
        "id": "ZSpIPbLG-Vcw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to compare images using SSIM + Pixel Difference\n",
        "def is_touch_detected(baseline_image, new_image, ssim_threshold=0.8, pixel_change_threshold=5):\n",
        "    \"\"\"Uses both SSIM and pixel intensity difference to determine touch detection.\"\"\"\n",
        "    # Convert images to grayscale\n",
        "    baseline_gray = cv2.cvtColor(baseline_image, cv2.COLOR_BGR2GRAY)\n",
        "    new_gray = cv2.cvtColor(new_image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Compute Structural Similarity Index (SSIM)\n",
        "    similarity_score = ssim(baseline_gray, new_gray)\n",
        "\n",
        "    # Compute absolute pixel difference\n",
        "    diff = cv2.absdiff(baseline_gray, new_gray)\n",
        "    changed_pixels = np.sum(diff > 20)  # Count pixels with significant change (threshold 20)\n",
        "    total_pixels = diff.size\n",
        "    pixel_change_percent = (changed_pixels / total_pixels) * 100\n",
        "\n",
        "    logger.debug(f\"SSIM score: {similarity_score}, Pixel change: {pixel_change_percent:.2f}%\")\n",
        "\n",
        "    # If SSIM is low OR pixel difference is high, classify as touch\n",
        "    return similarity_score < ssim_threshold or pixel_change_percent > pixel_change_threshold"
      ],
      "metadata": {
        "id": "mf7xFO-_9jLl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. auto labeling\n"
      ],
      "metadata": {
        "id": "7lplwYXt--pY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Capture and auto-label images\n",
        "def capture_and_save_images(serial: str, save_path: str, num_images: int = 100, interval: float = 1.0):\n",
        "    yes_path = os.path.join(save_path, \"YES\")\n",
        "    no_path = os.path.join(save_path, \"NO\")\n",
        "    create_directory(yes_path)\n",
        "    create_directory(no_path)\n",
        "\n",
        "    csv_filename = os.path.join(save_path, \"labels.csv\")\n",
        "    csv_exists = os.path.exists(csv_filename)\n",
        "\n",
        "    with open(csv_filename, mode=\"a\", newline=\"\") as file:\n",
        "        writer = csv.writer(file)\n",
        "        if not csv_exists:\n",
        "            writer.writerow([\"filename\", \"label\"])  # Add header if file is new\n",
        "\n",
        "        # Connect to the DIGIT device\n",
        "        digit = Digit(serial)\n",
        "        digit.connect()\n",
        "\n",
        "        # Capture multiple baseline images (No Touch)\n",
        "        print(\"Ensure NO TOUCH for baseline image capture...\")\n",
        "        time.sleep(2)\n",
        "        baseline_images = []\n",
        "        for _ in range(3):  # Capture 3 baseline images for better reference\n",
        "            baseline_filename = os.path.join(save_path, f\"baseline_{_}.png\")\n",
        "            digit.save_frame(baseline_filename)\n",
        "            baseline_images.append(cv2.imread(baseline_filename))\n",
        "            time.sleep(0.5)\n",
        "\n",
        "        # Compute average baseline image\n",
        "        baseline_image = np.mean(np.array(baseline_images), axis=0).astype(np.uint8)\n",
        "        logger.info(\"Baseline images captured and averaged.\")\n",
        "\n",
        "        yes_count, no_count = 0, 0\n",
        "\n",
        "        for i in range(num_images):\n",
        "            try:\n",
        "                # Capture new frame\n",
        "                timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
        "                image_filename = f\"{save_path}/digit_{serial}_{timestamp}_{i+1}.png\"\n",
        "                digit.save_frame(image_filename)\n",
        "\n",
        "                # Read the newly captured image\n",
        "                new_image = cv2.imread(image_filename)\n",
        "\n",
        "                # Auto-label based on SSIM + Pixel Difference\n",
        "                if is_touch_detected(baseline_image, new_image):\n",
        "                    label = \"yes\"\n",
        "                    save_folder = yes_path\n",
        "                    yes_count += 1\n",
        "                else:\n",
        "                    label = \"no\"\n",
        "                    save_folder = no_path\n",
        "                    no_count += 1\n",
        "\n",
        "                # Move image to correct folder\n",
        "                new_image_path = os.path.join(save_folder, os.path.basename(image_filename))\n",
        "                os.rename(image_filename, new_image_path)\n",
        "\n",
        "                # Log filename and label in CSV\n",
        "                writer.writerow([new_image_path, label])\n",
        "                logger.info(f\"Image saved: {new_image_path} | Label: {label}\")\n",
        "\n",
        "                # Stop if 50 images per category are collected\n",
        "                if yes_count >= num_images // 2 and no_count >= num_images // 2:\n",
        "                    print(\"Collected required number of images for both categories.\")\n",
        "                    break\n",
        "\n",
        "                # Wait for the specified interval\n",
        "                time.sleep(interval)\n",
        "\n",
        "            except Exception as e:\n",
        "                logger.error(f\"Error capturing image {i+1}: {e}\")\n",
        "\n",
        "        # Disconnect the device\n",
        "        digit.disconnect()"
      ],
      "metadata": {
        "id": "rPjhiFvQKnGc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Define parameters\n",
        "    serial_number = \"D21114\"\n",
        "    #serial_number = \"D21115\"\n",
        "    save_directory = \"./captured_images\"\n",
        "    total_images = 100  # 50 YES and 50 NO images\n",
        "\n",
        "    # Start capturing images with auto-labeling\n",
        "    capture_and_save_images(serial_number, save_directory, num_images=total_images)"
      ],
      "metadata": {
        "id": "NZ3AwMAc9nw4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. counting captured images\n"
      ],
      "metadata": {
        "id": "T2zg3fQF_EqU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "def count_images_in_subfolders(root_folder):\n",
        "    \"\"\"Count the number of images in the YES and NO subfolders within the given root folder.\"\"\"\n",
        "    # Define the subfolder names\n",
        "    subfolders = ['YES', 'NO']\n",
        "\n",
        "    # Initialize the count dictionary\n",
        "    image_count = {'YES': 0, 'NO': 0}\n",
        "\n",
        "    # Check if root folder exists\n",
        "    if not os.path.exists(root_folder):\n",
        "        print(\"Error: Root folder not found.\")\n",
        "        return\n",
        "\n",
        "    # Loop through the subfolders (YES, NO)\n",
        "    for subfolder in subfolders:\n",
        "        subfolder_path = os.path.join(root_folder, subfolder)\n",
        "\n",
        "        # Check if subfolder exists\n",
        "        if os.path.exists(subfolder_path):\n",
        "            # Count the image files in the subfolder\n",
        "            for root_dir, _, files in os.walk(subfolder_path):\n",
        "                # Filter out image files (e.g., .jpg, .png, .jpeg)\n",
        "                image_files = [file for file in files if file.lower().endswith(('.jpg', '.jpeg', '.png', '.gif', '.bmp'))]\n",
        "                image_count[subfolder] += len(image_files)\n",
        "\n",
        "    # Print the results\n",
        "    print(f\"Images in 'YES' folder: {image_count['YES']}\")\n",
        "    print(f\"Images in 'NO' folder: {image_count['NO']}\")\n",
        "    print(f\"Total images: {image_count['YES'] + image_count['NO']}\")\n",
        "\n",
        "# Example Usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Specify the path to the captured_images folder\n",
        "    captured_images_folder = \"./captured_images\"\n",
        "    count_images_in_subfolders(captured_images_folder)\n"
      ],
      "metadata": {
        "id": "yf_Ffy0FKjN9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. display an image"
      ],
      "metadata": {
        "id": "wWe_YdE1_pvO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def show_image(category):\n",
        "    \"\"\"\n",
        "    Display an image from the specified category (YES/NO) in the 'captured_images' folder.\n",
        "    \"\"\"\n",
        "    folder_path = os.path.join(\"captured_images\", category.upper())\n",
        "    if not os.path.exists(folder_path):\n",
        "        print(f\"Error: Folder '{folder_path}' not found.\")\n",
        "        return\n",
        "\n",
        "    images = [img for img in os.listdir(folder_path) if img.endswith(\".png\")]\n",
        "    if not images:\n",
        "        print(f\"No images found in {folder_path}\")\n",
        "        return\n",
        "\n",
        "    image_path = os.path.join(folder_path, images[0])\n",
        "    image = cv2.imread(image_path)\n",
        "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    plt.imshow(image_rgb)\n",
        "    plt.title(f\"Class: {category}\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "19kGa2Ec_mKh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. display image information"
      ],
      "metadata": {
        "id": "8tTZmnwW_zzo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def show_image_info(image_path):\n",
        "    \"\"\"\n",
        "    Display image information including size, type, datatype, number of pixels, and channels.\n",
        "    \"\"\"\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is None:\n",
        "        print(\"Error: Could not read image.\")\n",
        "        return\n",
        "\n",
        "    height, width, channels = image.shape\n",
        "    size = os.path.getsize(image_path)\n",
        "    dtype = image.dtype\n",
        "    total_pixels = height * width\n",
        "\n",
        "    print(f\"Image Path: {image_path}\")\n",
        "    print(f\"Size: {size} bytes\")\n",
        "    print(f\"Type: {type(image)}\")\n",
        "    print(f\"Data Type: {dtype}\")\n",
        "    print(f\"height, width, channels: ({height},{width},{channels})\")\n",
        "    print(f\"Total Pixels: {total_pixels}\")\n",
        "    print(f\"Channels: {channels}\")\n",
        "\n",
        "# Example Usage\n",
        "if __name__ == \"__main__\":\n",
        "    show_image(\"YES\")\n",
        "    show_image(\"NO\")\n",
        "    example_image_path = \"captured_images/YES/digit_D21115_20250210_152012_35.png\"\n",
        "    show_image_info(example_image_path)\n"
      ],
      "metadata": {
        "id": "9Y5Ii15BKh1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " 7. creating model class"
      ],
      "metadata": {
        "id": "1wnUNztdABUf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "# Creating a CNN class\n",
        "class ConvNeuralNet(nn.Module):\n",
        "#  Determine what layers and their order in CNN object\n",
        "    def __init__(self, num_classes):\n",
        "        super(ConvNeuralNet, self).__init__()\n",
        "        self.conv_layer1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3)\n",
        "        self.conv_layer2 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3)\n",
        "        self.max_pool1 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
        "\n",
        "        self.conv_layer3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3)\n",
        "        self.conv_layer4 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3)\n",
        "        self.max_pool2 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
        "\n",
        "        self.fc1 = nn.Linear(1600, 128)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(128, num_classes)\n",
        "\n",
        "    # Progresses data across layers\n",
        "    def forward(self, x):\n",
        "        out = self.conv_layer1(x)\n",
        "        out = self.conv_layer2(out)\n",
        "        out = self.max_pool1(out)\n",
        "\n",
        "        out = self.conv_layer3(out)\n",
        "        out = self.conv_layer4(out)\n",
        "        out = self.max_pool2(out)\n",
        "\n",
        "        out = out.reshape(out.size(0), -1)\n",
        "\n",
        "        out = self.fc1(out)\n",
        "        out = self.relu1(out)\n",
        "        out = self.fc2(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "_tKSr7mJKYkr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. define loss function and optimizer"
      ],
      "metadata": {
        "id": "ob8GIVUCAgR6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MrosD2AcKKqG"
      },
      "outputs": [],
      "source": [
        "model = ConvNeuralNet(num_classes)\n",
        "# Set Loss function with criterion\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Set optimizer with optimizer\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay = 0.005, momentum = 0.9)\n",
        "total_step = len(train_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. define variables for ML"
      ],
      "metadata": {
        "id": "CiRTR70pAzqG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define relevant variables for the ML task\n",
        "batch_size = 64\n",
        "num_classes = 1\n",
        "learning_rate = 0.001\n",
        "num_epochs = 20\n",
        "\n",
        "# Device will determine whether to run the training on GPU or CPU.\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
      ],
      "metadata": {
        "id": "QMqtJ4kNKZ7A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. training"
      ],
      "metadata": {
        "id": "Af14PNU6BLyy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "num_epochs = 10  # Change this based on your training setting\n",
        "losses = []  # Store loss values for visualization\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    epoch_loss = 0  # Track total loss in an epoch\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()  # Accumulate loss\n",
        "\n",
        "    avg_loss = epoch_loss / len(train_loader)  # Compute average loss per epoch\n",
        "    losses.append(avg_loss)  # Store for visualization\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}')\n",
        "\n",
        "# Loss Plot\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(range(1, num_epochs+1), losses, marker='o', linestyle='-')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss vs. Epochs')\n",
        "plt.grid()\n",
        "\n",
        "# Visualization of the learning rate effect\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.plot(range(1, num_epochs+1), losses, marker='o', linestyle='-')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss vs. Epochs (Learning Rate Effect)')\n",
        "plt.grid()\n",
        "\n",
        "# Accuracy Plot\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(range(1, num_epochs+1), accuracies, marker='s', linestyle='-', color='g')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.title('Accuracy vs. Epochs')\n",
        "plt.grid()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "idV7qynaKc2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in train_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print('Accuracy of the network on the {} train images: {} %'.format(50000, 100 * correct / total))"
      ],
      "metadata": {
        "id": "5MKmE3WpKedy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}