{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPcDa+ma5lpSPuDaNxtRS5n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Morsalah/M.Sc-Research-HRI-using-DIGIT-tactile-sensor/blob/main/Image_Classificcation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Basic CNN"
      ],
      "metadata": {
        "id": "wESt73YW6rB4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SxW-9cOe6j0-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class MyModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv_layers = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.AdaptiveAvgPool2d(1)  # Global Average Pooling\n",
        "        )\n",
        "\n",
        "        self.fc_layers = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),  # Dropout for regularization\n",
        "            nn.Linear(128, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_layers(x)\n",
        "        x = self.fc_layers(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data loader test"
      ],
      "metadata": {
        "id": "Hnaap_sI600v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from dataloader import calculate_mean_std\n",
        "\n",
        "val_test_transform = transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=mean.tolist(), std=std.tolist())\n",
        "                                        ])\n",
        "\n",
        "# Custom dataset to load images without labels\n",
        "class UnlabeledDataset(Dataset):\n",
        "    def __init__(self, image_folder, transform=None):\n",
        "        self.image_folder = image_folder\n",
        "        self.image_files = [os.path.join(image_folder, f) for f in os.listdir(image_folder) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_files[idx]\n",
        "        image = Image.open(img_path).convert(\"RGB\")  # Ensure 3-channel RGB\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, img_path  # Return image + filename for reference\n",
        "\n",
        "# Load test dataset\n",
        "test_folder = \"./test_data\"\n",
        "test_dataset = UnlabeledDataset(test_folder, transform=test_transforms)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)  # No shuffle!\n"
      ],
      "metadata": {
        "id": "8uhxttRM63md"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "data loader"
      ],
      "metadata": {
        "id": "lWuwL_z07JNs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from hyperparamters_variables import Batch_size\n",
        "\n",
        "def calculate_mean_std(loader):\n",
        "    \"\"\"Calculate mean and standard deviation of dataset.\"\"\"\n",
        "    mean = 0.\n",
        "    std = 0.\n",
        "    total_images_count = 0\n",
        "\n",
        "    for images, _ in loader:\n",
        "        images = images.view(images.size(0), images.size(1), -1)\n",
        "        mean += images.mean(2).sum(0)\n",
        "        std += images.std(2).sum(0)\n",
        "        total_images_count += images.size(0)\n",
        "\n",
        "    mean /= total_images_count\n",
        "    std /= total_images_count\n",
        "\n",
        "    return mean, std\n",
        "\n",
        "def create_transformed_dataset(input_dir, transform):\n",
        "    \"\"\"Create dataset with transformed images.\"\"\"\n",
        "    transformed_dataset = ImageFolder(root=input_dir, transform=transform)\n",
        "    return transformed_dataset\n",
        "\n",
        "initial_transform = transforms.Compose([transforms.Resize(224),\n",
        "                                        transforms.ToTensor()])\n",
        "# Create the initial training dataset\n",
        "initial_train_dataset = ImageFolder(root='./split_dataset/train',\n",
        "                                    transform=initial_transform)\n",
        "\n",
        "initial_train_loader = DataLoader(initial_train_dataset,\n",
        "                                  batch_size=Batch_size,\n",
        "                                  shuffle=True)\n",
        "\n",
        "mean, std = calculate_mean_std(initial_train_loader)\n",
        "\n",
        "# Define transformations with calculated mean and std\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=mean.tolist(), std=std.tolist())\n",
        "])\n",
        "\n",
        "val_test_transform = transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=mean.tolist(), std=std.tolist())\n",
        "])\n",
        "\n",
        "# Create transformed dataset directories for train, val, and test sets\n",
        "train_dataset = create_transformed_dataset('./split_dataset/train',\n",
        "                                            train_transform)\n",
        "\n",
        "val_dataset = create_transformed_dataset('./split_dataset/val',\n",
        "                                          val_test_transform)\n",
        "\n",
        "# Create data loaders for train, val, and test datasets\n",
        "train_loader = DataLoader(train_dataset,\n",
        "                          batch_size=Batch_size,\n",
        "                          shuffle=True)\n",
        "\n",
        "val_loader = DataLoader(val_dataset,\n",
        "                        batch_size=Batch_size,\n",
        "                        shuffle=False)\n",
        "\n",
        "# Verifying creation of data loaders\n",
        "#print(type(train_loader), type(val_loader), type(test_loader))\n",
        "\n",
        "'''\n",
        "# Check if data loaders contain batches\n",
        "for images, labels in train_loader:\n",
        "    print(f\"image shape {images.shape}\")\n",
        "    print(f\"label shape {labels.shape}\")\n",
        "    break\n",
        "\n",
        "print(f\"Batch size of train_loader: {train_loader.batch_size}\")\n",
        "print(f\"Batch size of val_loader: {val_loader.batch_size}\")\n",
        "print(f\"Batch size of test_loader: {test_loader.batch_size}\")\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "Q_48QdSq7LW9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "heperparamters variables"
      ],
      "metadata": {
        "id": "AiP1-vvQ7NaV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import Adam\n",
        "from BasicCNN import MyModel\n",
        "from torchsummary import summary\n",
        "\n",
        "# HyperParamters\n",
        "Batch_size = 128\n",
        "Ratio = [0.7,0.2,0.1]\n",
        "Epoches = 30\n",
        "Learning_rate = 0.0001\n",
        "\n",
        "# Model Initialization\n",
        "model = MyModel()\n",
        "\n",
        "# Using Device\n",
        "DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(DEVICE)\n",
        "image = (3, 224, 224)\n",
        "\n",
        "# Loss Function and Optimizer\n",
        "\n",
        "optimizer = Adam(model.parameters(), lr=Learning_rate)\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=Learning_rate, weight_decay=1e-4)\n",
        "\n",
        "loss_fun = nn.BCEWithLogitsLoss()\n",
        "\n",
        "model_architecture = summary(model,image)\n",
        "# Print Model Summary\n",
        "# print(summary(model,image))\n",
        "\n"
      ],
      "metadata": {
        "id": "kkkNvsGk7Qsu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "loss accuracy results"
      ],
      "metadata": {
        "id": "mNbIKa6X7Sa2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import time\n",
        "from datetime import datetime\n",
        "from matplotlib import pyplot as plt\n",
        "from dataloader import train_loader, val_loader\n",
        "from main_function import main\n",
        "from hyperparamters_variables import Epoches, Learning_rate, Batch_size, Ratio, optimizer, loss_fun, model, model_architecture\n",
        "\n",
        "def experiment(experiment_id):\n",
        "    experiment_folder = f\"./experiment_results/experiment_{experiment_id}_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
        "    os.makedirs(experiment_folder, exist_ok=True)\n",
        "\n",
        "    train_losses, train_accuracies, val_losses, val_accuracies = main(model, train_loader, val_loader, Epoches)\n",
        "\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    # Plot training and validation loss\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(range(1, Epoches + 1), train_losses, label=\"Train Loss\")\n",
        "    plt.plot(range(1, Epoches + 1), val_losses, label=\"Validation Loss\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.title(\"Loss vs Epochs\")\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot training and validation accuracy\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(range(1, Epoches + 1), train_accuracies, label=\"Train Accuracy\")\n",
        "    plt.plot(range(1, Epoches + 1), val_accuracies, label=\"Validation Accuracy\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.title(\"Accuracy vs Epochs\")\n",
        "    plt.legend()\n",
        "\n",
        "    # Save the plot before displaying\n",
        "    plot_filename = os.path.join(experiment_folder, \"experiment_plots.png\")\n",
        "    plt.savefig(plot_filename)  # Save the plot\n",
        "\n",
        "    plt.close()  # Close the figure to free memory\n",
        "\n",
        "    # Prepare experiment details\n",
        "    experiment_details = {\n",
        "        \"Experiment_ID\": experiment_id,\n",
        "        \"Train_Test_Split\": f\"train={Ratio[0]}, val={Ratio[1]}, test={Ratio[2]}\",\n",
        "        \"Model\": print(model_architecture),\n",
        "        \"Optimizer\": optimizer.__class__.__name__,\n",
        "        \"Loss_Function\": loss_fun.__class__.__name__,\n",
        "        \"Learning_Rate\": Learning_rate,\n",
        "        \"Epochs\": Epoches,\n",
        "        \"Batch_Size\": Batch_size,\n",
        "        \"Train_Losses\": train_losses,\n",
        "        \"Train_Accuracies\": train_accuracies,\n",
        "        \"Val_Losses\": val_losses,\n",
        "        \"Val_Accuracies\": val_accuracies\n",
        "    }\n",
        "\n",
        "    # Save experiment details as a JSON file\n",
        "    json_filename = os.path.join(experiment_folder, \"experiment_details.json\")\n",
        "    with open(json_filename, 'w') as f:\n",
        "        json.dump(experiment_details, f, indent=4)\n",
        "\n",
        "    print(f\"Experiment results saved in {experiment_folder}\")\n",
        "    return experiment_folder\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    experiment_id = f\"exp_{int(time.time())}\"  # Generates a unique ID based on the current timestamp\n",
        "    experiment_folder = experiment(experiment_id)\n"
      ],
      "metadata": {
        "id": "kMFT4FLt7WaH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "main function"
      ],
      "metadata": {
        "id": "5MkRGlVC7fnB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from train_function import train\n",
        "from validation_function import validation\n",
        "from hyperparamters_variables import Epoches\n",
        "\n",
        "def main(model, train_loader, val_loader,Epoches):\n",
        "\n",
        "    train_losses, val_losses = [], []\n",
        "    train_accuracies, val_accuracies = [], []\n",
        "\n",
        "    for epoch in range(Epoches):\n",
        "        train_loss, train_accuracy = train(model, train_loader)\n",
        "        val_loss, val_accuracy = validation(model, val_loader)\n",
        "\n",
        "        train_losses.append(train_loss)\n",
        "        train_accuracies.append(train_accuracy)\n",
        "        val_losses.append(val_loss)\n",
        "        val_accuracies.append(val_accuracy)\n",
        "\n",
        "        print(f\"Epoch {epoch+1:0>2}/{Epoches} - Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}% - Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%\")\n",
        "\n",
        "    return train_losses, train_accuracies, val_losses, val_accuracies"
      ],
      "metadata": {
        "id": "EeoPIidC7hJ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "first CNN implementation"
      ],
      "metadata": {
        "id": "L86eztKW7lM4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "class MyModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv_layers = nn.Sequential(\n",
        "            # Block 1\n",
        "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2),\n",
        "            # block2\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2),\n",
        "            # block3\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2),\n",
        "            # block4\n",
        "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2),\n",
        "        )\n",
        "\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "        # Compute the in_features dynamically\n",
        "        with torch.no_grad():\n",
        "            dummy_input = torch.zeros(1, 3, 224, 224)\n",
        "            dummy_output = self.conv_layers(dummy_input)\n",
        "            self.in_features = dummy_output.view(1, -1).shape[1]\n",
        "\n",
        "        self.fc_layers = nn.Sequential(\n",
        "            nn.Linear(self.in_features, 256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(256, 1),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_layers(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc_layers(x)\n",
        "        return x\n",
        "'''\n",
        "\n",
        "'''\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class MyModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv_layers = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.AdaptiveAvgPool2d(1)  # Global Average Pooling\n",
        "        )\n",
        "\n",
        "        self.fc_layers = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),  # Dropout for regularization\n",
        "            nn.Linear(128, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_layers(x)\n",
        "        x = self.fc_layers(x)\n",
        "        return x\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "o34A2XQX7o1S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "performance results"
      ],
      "metadata": {
        "id": "m2e4W9ra7qhy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from hyperparamters_variables import DEVICE\n",
        "\n",
        "def predict_images(model, test_loader):\n",
        "    model.eval()\n",
        "    model.to(DEVICE)\n",
        "\n",
        "    predicted_labels, predicted_probs, image_paths = [], [], []\n",
        "\n",
        "    for images, paths in test_loader:\n",
        "        images = images.to(DEVICE)\n",
        "\n",
        "        with torch.inference_mode():\n",
        "            outputs = model(images)\n",
        "        prob = torch.sigmoid(outputs)\n",
        "        pred_indices = (prob > 0.5).long().squeeze()\n",
        "        pred_probs = prob.squeeze()\n",
        "\n",
        "        # Store results\n",
        "        predicted_labels.extend(pred_indices.cpu().numpy())\n",
        "        predicted_probs.extend(pred_probs.cpu().numpy())\n",
        "        image_paths.extend(paths)\n",
        "\n",
        "    return image_paths, np.array(predicted_labels), np.array(predicted_probs)\n"
      ],
      "metadata": {
        "id": "tHyviGK07tjc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "train function"
      ],
      "metadata": {
        "id": "gcLeGV2J7y2s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from hyperparamters_variables import optimizer,loss_fun,DEVICE,model\n",
        "from tqdm import tqdm\n",
        "\n",
        "def train(model, train_loader):\n",
        "    model.train()\n",
        "    model.to(DEVICE)\n",
        "    running_loss = 0\n",
        "    correct_predictions = 0\n",
        "    total_train_samples = 0\n",
        "\n",
        "    for images, labels in tqdm(train_loader, desc=\"Training\"):\n",
        "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = loss_fun(outputs, labels.float().unsqueeze(1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        # Convert logits to probabilities and apply threshold\n",
        "        predictions = torch.sigmoid(outputs) > 0.5\n",
        "        correct_predictions += (predictions == labels.unsqueeze(1)).sum().item()\n",
        "        total_train_samples += labels.size(0)\n",
        "\n",
        "    train_avg_loss = running_loss / len(train_loader)\n",
        "    train_accuracy = 100 * correct_predictions / total_train_samples\n",
        "\n",
        "    return train_avg_loss, train_accuracy\n"
      ],
      "metadata": {
        "id": "QXTAlmIw70fF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "validation function"
      ],
      "metadata": {
        "id": "E3gSsI-d72BF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "from hyperparamters_variables import loss_fun,DEVICE,model\n",
        "\n",
        "def validation(model, val_loader):\n",
        "    model.eval()\n",
        "    model.to(DEVICE)\n",
        "\n",
        "    running_loss = 0\n",
        "    correct_predictions = 0\n",
        "    total_val_samples = 0\n",
        "\n",
        "    for images, labels in tqdm(val_loader, desc=\"Validation\"):\n",
        "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "\n",
        "        with torch.no_grad():\n",
        "             outputs = model(images)\n",
        "\n",
        "        loss = loss_fun(outputs, labels.float().unsqueeze(1))\n",
        "        running_loss += loss.item()\n",
        "        #_, predicted = torch.max(outputs.data, dim=1)\n",
        "        predicted = torch.round(torch.sigmoid(outputs.data)).squeeze(1)\n",
        "        #labels = labels.squeeze(1)\n",
        "        total_val_samples += labels.shape[0]\n",
        "        correct_predictions += (predicted == labels).sum().item()\n",
        "\n",
        "    val_avg_loss = running_loss / len(val_loader)\n",
        "    val_accuracy = 100 * correct_predictions / total_val_samples\n",
        "    return val_avg_loss, val_accuracy"
      ],
      "metadata": {
        "id": "eJqfYcVp734u"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}