{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOyUZTKHp9Hi6n2lkbAsZGg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Morsalah/M.Sc-Research-HRI-using-DIGIT-tactile-sensor/blob/main/Intro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Enhanced Object Manipulation\n",
        "Grasping and Holding Objects:\n",
        "\n",
        "DIGIT sensors provide high-resolution tactile feedback that allows robots to determine the appropriate amount of force required to grasp and hold objects without damaging them.\n",
        "Example: Handling delicate items like glassware or soft materials during collaborative tasks with humans.\n",
        "\n",
        "* Surface Exploration:\n",
        "Robots can use the DIGIT sensor to perceive surface textures and irregularities, improving their ability to differentiate between objects or materials.\n",
        "Example: Detecting whether a surface is rough, smooth, or slippery, and adjusting actions accordingly.\n",
        "Slip Detection:\n",
        "\n",
        "By sensing micro-movements between the robotâ€™s gripper and the object, DIGIT sensors can detect when an object is slipping, prompting the robot to adjust its grip in real-time.\n",
        "Example: Preventing objects from falling during transportation in industrial or healthcare settings."
      ],
      "metadata": {
        "id": "LpEw3OEB4jZh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Tactile-Based Action Recognition\n",
        "Human Touch Recognition:\n",
        "\n",
        "DIGIT sensors can detect and interpret human touch patterns, enabling robots to understand gestures, signals, or intentions.\n",
        "Example: A robot identifying a light tap or a press as a signal to start or stop an action in an assistive setting.\n",
        "Task-Specific Feedback:\n",
        "\n",
        "The sensor can be used to detect forces and pressures during task-specific interactions, such as writing, assembling parts, or applying adhesives.\n",
        "Example: Monitoring pressure during precision tasks like medical suturing or assembly-line work."
      ],
      "metadata": {
        "id": "xlBmaosRDkIM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Learning from Demonstration\n",
        "Skill Transfer:\n",
        "\n",
        "DIGIT sensors allow robots to learn tasks from human demonstrations by capturing detailed tactile data during the interaction.\n",
        "Example: A human showing the robot how to pick up fragile items, with the robot replicating the pressure and motions based on tactile feedback.\n",
        "Real-Time Adaptation:\n",
        "\n",
        "The robot can adjust its actions dynamically, learning optimal force application and grip patterns during repetitive tasks.\n",
        "Example: Adapting to varying object weights or shapes in real-world scenarios."
      ],
      "metadata": {
        "id": "jOrgQv3uDqSx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Safety and Responsiveness in Collaborative Environments\n",
        "Collision Detection:\n",
        "\n",
        "The DIGIT sensor can detect unintended contact between a robot and its surroundings, improving safety in shared workspaces.\n",
        "Example: Detecting and responding to accidental bumps with a human coworker in an industrial setting.\n",
        "Soft Object Interaction:\n",
        "\n",
        "Robots equipped with DIGIT sensors can handle soft objects (e.g., foam, fabrics, or biological tissues) with care, making them suitable for tasks like caregiving or surgery.\n",
        "Example: Assisting in dressing a patient or handling fragile biological samples.\n"
      ],
      "metadata": {
        "id": "kQDj5StWDtrH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Multimodal Sensing for Richer Interaction\n",
        "Integration with Computer Vision:\n",
        "\n",
        "Combining DIGIT sensors with computer vision enables robots to utilize both tactile and visual data for decision-making.\n",
        "Example: A robot identifying an object visually, then using tactile sensors to assess its material properties for more accurate manipulation.\n",
        "Haptic Feedback for Humans:\n",
        "\n",
        "The sensor data can be processed and returned as haptic feedback in teleoperation scenarios, enabling human operators to feel the forces and textures the robot experiences.\n",
        "Example: A surgeon remotely controlling a robotic arm and feeling the texture of tissues during a minimally invasive procedure."
      ],
      "metadata": {
        "id": "TNEuVuxsDwzq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Advanced Applications in HRI\n",
        "Rehabilitation and Prosthetics:\n",
        "\n",
        "DIGIT sensors can be embedded in robotic prosthetics to provide users with tactile feedback, improving control and enhancing the sense of touch.\n",
        "Example: Allowing a prosthetic hand to detect object texture and pressure, giving the user a more natural interaction experience.\n",
        "Robotic Companions:\n",
        "\n",
        "In social robotics, tactile sensors help robots respond appropriately to human touch, making interactions more intuitive and emotionally engaging.\n",
        "Example: A companion robot recognizing and reacting to a comforting pat on the head or a hand squeeze.\n",
        "Education and Training:\n",
        "\n",
        "Robots equipped with DIGIT sensors can assist in training humans by providing real-time tactile feedback and evaluation.\n",
        "Example: Teaching students precise hand movements for crafting or surgery by mimicking and analyzing their actions."
      ],
      "metadata": {
        "id": "Up2NjK0rD0Ca"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Capturing Data from DIGIT"
      ],
      "metadata": {
        "id": "OfLrgaoRqUJq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A9tzItxzqBzS"
      },
      "outputs": [],
      "source": [
        "from digit_interface import Digit\n",
        "\n",
        "# Initialize DIGIT sensor\n",
        "digit = Digit(\"DIGIT_SERIAL_NUMBER\")  # Replace with your DIGIT serial number\n",
        "digit.connect()\n",
        "\n",
        "# Capture an image\n",
        "tactile_image = digit.get_frame()\n",
        "\n",
        "# Save the image for further processing\n",
        "import cv2\n",
        "cv2.imwrite(\"tactile_image.jpg\", tactile_image)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Preprocessing data\n",
        "* Normalize the tactile image data.\n",
        "* Convert images into tensors for training models."
      ],
      "metadata": {
        "id": "Zvpw6aysqfff"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Model Building\n",
        "* choosing the DL model (YOLO/CNN)"
      ],
      "metadata": {
        "id": "7Ih9Az7Sq3Xs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Model Training"
      ],
      "metadata": {
        "id": "Va1DBiQGrLKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Testing and Evaluation"
      ],
      "metadata": {
        "id": "SNVToAcrq7wH"
      }
    }
  ]
}