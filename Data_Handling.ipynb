{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPRKUre1X1Wb4DOEmd2ewDf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Morsalah/M.Sc-Research-HRI-using-DIGIT-tactile-sensor/blob/main/Data_Handling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "walking through data set"
      ],
      "metadata": {
        "id": "oPJDND1v46JE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lhuba9s-4ret"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import shutil\n",
        "\n",
        "def walk_through_folders(base_path, dataset_path):\n",
        "    \"\"\"Walk through YES and NO folders, copy images to dataset, rename them accordingly, and store in a DataFrame.\"\"\"\n",
        "    folders = ['YES', 'NO']\n",
        "    data = []\n",
        "    seen_filenames = {}  # To avoid overwriting files with the same timestamp\n",
        "\n",
        "    # Ensure dataset directory exists\n",
        "    os.makedirs(dataset_path, exist_ok=True)\n",
        "\n",
        "    for folder in folders:\n",
        "        folder_path = os.path.join(base_path, folder)\n",
        "        if os.path.exists(folder_path):\n",
        "            for root, _, files in os.walk(folder_path):\n",
        "                for file in sorted(files):  # Keep order consistent\n",
        "                    if file.lower().endswith(('png', 'jpg', 'jpeg')):  # Filter only image files\n",
        "                        original_path = os.path.join(root, file)\n",
        "                        relative_path = os.path.relpath(original_path, base_path)\n",
        "\n",
        "                        # Extract timestamp from filename (assuming the format includes \"_D21114_20250217_094231_\")\n",
        "                        parts = file.split('_')\n",
        "                        timestamp = parts[2] if len(parts) >= 4 else \"unknown\"\n",
        "\n",
        "                        # Prevent overwriting: Append index if filename exists\n",
        "                        if timestamp in seen_filenames:\n",
        "                            seen_filenames[timestamp] += 1\n",
        "                            new_filename = f\"{timestamp}_{folder.lower()}_{seen_filenames[timestamp]}.png\"\n",
        "                        else:\n",
        "                            seen_filenames[timestamp] = 1\n",
        "                            new_filename = f\"{timestamp}_{folder.lower()}.png\"\n",
        "\n",
        "                        new_path = os.path.join(dataset_path, new_filename)\n",
        "\n",
        "                        # Copy and rename image to dataset directory\n",
        "                        shutil.copy2(original_path, new_path)\n",
        "\n",
        "                        data.append({\n",
        "                            'Original_Folder': folder,\n",
        "                            'Original_Image_Path': relative_path,\n",
        "                            'New_Image_Path': new_path,\n",
        "                            'New_Filename': new_filename\n",
        "                        })\n",
        "\n",
        "    # Create DataFrame\n",
        "    df = pd.DataFrame(data)\n",
        "    print(f\"Processed {len(df)} images.\")\n",
        "    return df\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    base_directory = \"./captured_images\"\n",
        "    dataset_directory = \"./dataset\"\n",
        "    df_images = walk_through_folders(base_directory, dataset_directory)\n",
        "\n",
        "    # Save to CSV\n",
        "    df_images.to_csv(os.path.join(base_directory, \"captured_images_summary.csv\"), index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "spliting data"
      ],
      "metadata": {
        "id": "1M4yH5ps5A0d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "\n",
        "def split_dataset(input_dir, output_dir, train_ratio, val_ratio, test_ratio, overwrite=True):\n",
        "    \"\"\"Split dataset into train/val/test while organizing images into 'yes' and 'no' subfolders.\"\"\"\n",
        "\n",
        "    # Ensure input directory exists\n",
        "    if not os.path.exists(input_dir):\n",
        "        print(f\"Error: Input directory '{input_dir}' does not exist!\")\n",
        "        return\n",
        "\n",
        "    # Remove and recreate output directory if overwrite is enabled\n",
        "    if os.path.exists(output_dir) and overwrite:\n",
        "        print(f\"Removing existing directory: {output_dir}\")\n",
        "        shutil.rmtree(output_dir)\n",
        "\n",
        "    # Prepare output directories\n",
        "    subsets = ['train', 'val', 'test']\n",
        "    classes = ['yes', 'no']\n",
        "\n",
        "    for subset in subsets:\n",
        "        for cls in classes:\n",
        "            os.makedirs(os.path.join(output_dir, subset, cls), exist_ok=True)\n",
        "\n",
        "    # Collect all images\n",
        "    images = [f for f in os.listdir(input_dir) if f.lower().endswith('png')]\n",
        "\n",
        "    # Split dataset\n",
        "    train_images, temp_images = train_test_split(images, train_size=train_ratio, random_state=42)\n",
        "    val_images, test_images = train_test_split(temp_images, train_size=val_ratio / (val_ratio + test_ratio), random_state=42)\n",
        "\n",
        "    # Function to move files\n",
        "    def move_files(image_list, subset_name):\n",
        "        for img in tqdm(image_list, desc=f\"Processing {subset_name}\"):\n",
        "            # Determine class based on filename\n",
        "            cls = 'yes' if 'yes' in img.lower() else 'no'\n",
        "            src = os.path.join(input_dir, img)\n",
        "            dst = os.path.join(output_dir, subset_name, cls, img)\n",
        "            shutil.copy(src, dst)\n",
        "\n",
        "    # Move files to respective folders\n",
        "    move_files(train_images, 'train')\n",
        "    move_files(val_images, 'val')\n",
        "    move_files(test_images, 'test')\n",
        "\n",
        "    # Print summary\n",
        "    print(\"\\nDataset split complete!\")\n",
        "    print(f\"Training: {len(train_images)} images\")\n",
        "    print(f\"Validation: {len(val_images)} images\")\n",
        "    print(f\"Testing: {len(test_images)} images\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    dataset_directory = \"./dataset\"  # Folder containing all images (not sorted)\n",
        "    output_directory = \"./split_dataset\"  # Output folder for organized dataset\n",
        "\n",
        "    split_dataset(dataset_directory, output_directory, train_ratio=0.7, val_ratio=0.2, test_ratio=0.1, overwrite=True)\n"
      ],
      "metadata": {
        "id": "Jv4GkBe2424l"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}